{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a9d33a-68af-446e-9630-1b0656ef7844",
   "metadata": {
    "id": "77a9d33a-68af-446e-9630-1b0656ef7844"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54862a76-b52d-49f7-8daf-bead24f421c7",
   "metadata": {
    "id": "54862a76-b52d-49f7-8daf-bead24f421c7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "# NLTK Packages\n",
    "import nltk\n",
    "#nltk.download( 'vader_lexicon' )\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "# Spacy Packages\n",
    "import spacy\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "# Models used for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# Feature Extractor for text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#import skipthoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4e008-5218-4aaa-9fe2-e28bd705d154",
   "metadata": {
    "id": "29f4e008-5218-4aaa-9fe2-e28bd705d154"
   },
   "outputs": [],
   "source": [
    "## Import Data\n",
    "#C:\\Users\\coope\\Data_Science\\Datasets\\Yelp\\Json\n",
    "#C:\\Users\\coope\\Data_Science\\Datasets\\Yelp\\Json\\yelp_academic_dataset_business.json\n",
    "input_path_business_info = 'C:\\\\Users\\\\coope\\\\Data_Science\\\\Datasets\\\\Yelp\\\\Json\\\\yelp_academic_dataset_business.json'\n",
    "input_path_review_data = 'C:\\\\Users\\\\coope\\\\Data_Science\\\\Datasets\\\\Yelp\\\\Json\\\\yelp_academic_dataset_review.json'\n",
    "output_path_business_id = 'C:\\\\Users\\\\coope\\\\Data_Science\\\\Datasets\\\\Yelp\\\\business_id.csv'\n",
    "output_path_total_data = 'C:\\\\Users\\\\coope\\\\Data_Science\\\\Datasets\\\\Yelp\\\\total_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5a6dd-427e-4cd5-b5e2-4768a633f3a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "10e5a6dd-427e-4cd5-b5e2-4768a633f3a7",
    "outputId": "dbe345b4-9335-48cd-93c5-18df1c874e3f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(input_path_business_info, lines = True)\n",
    "\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcfdcc-0cd2-4eeb-ae92-89af82f990bf",
   "metadata": {
    "id": "cbdcfdcc-0cd2-4eeb-ae92-89af82f990bf"
   },
   "outputs": [],
   "source": [
    "resturants = df[df[\"categories\"].str.contains(\"Restaurants\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c5857-a464-4112-ba57-5b5de8533f18",
   "metadata": {
    "id": "939c5857-a464-4112-ba57-5b5de8533f18"
   },
   "outputs": [],
   "source": [
    "res_id = resturants[\"business_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb400f67-d122-41f0-9d60-167c9f6a95bc",
   "metadata": {
    "id": "bb400f67-d122-41f0-9d60-167c9f6a95bc"
   },
   "outputs": [],
   "source": [
    "chunks = pd.read_json(path_review, lines = True, chunksize = 10000)\n",
    "#i = 0\n",
    "total_data = pd.DataFrame()\n",
    "\n",
    "for chunk in chunks:\n",
    "    #if i >= 500:\n",
    "        #break\n",
    "    #i += 1\n",
    "    resturant = chunk[chunk[\"business_id\"].isin(res_id)][[\"stars\", \"text\"]]\n",
    "    total_data = pd.concat([total_data, resturant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ddfc61-51b9-420a-840b-e36cbb45e523",
   "metadata": {
    "id": "d6ddfc61-51b9-420a-840b-e36cbb45e523"
   },
   "outputs": [],
   "source": [
    "total_data[\"text\"][0]\n",
    "total_data[\"stars\"][0]\n",
    "\n",
    "total_data.to_csv(output_path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62800780-2bed-474f-8b33-dffdceb42aed",
   "metadata": {
    "id": "62800780-2bed-474f-8b33-dffdceb42aed"
   },
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673a4c2-f41b-4837-ab4e-f3bce0d203e8",
   "metadata": {
    "id": "e673a4c2-f41b-4837-ab4e-f3bce0d203e8"
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\yelp_dataset\\\\total_data.csv'\n",
    "out_path_binary = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\Raw Data\\\\Yelp Data\\\\binary.csv'\n",
    "out_path_nominal = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\Raw Data\\\\Yelp Data\\\\nominal.csv'\n",
    "\n",
    "df = pd.read_csv(path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed542e1-2393-435f-bdee-8abe814f1dc0",
   "metadata": {
    "id": "aed542e1-2393-435f-bdee-8abe814f1dc0"
   },
   "outputs": [],
   "source": [
    "plt.hist(df[\"stars\"])\n",
    "plt.show()\n",
    "\n",
    "pd.crosstab(index = df[\"stars\"], columns = \"prop\") / pd.crosstab(index = df[\"stars\"], columns = \"prop\").sum()\n",
    "pd.crosstab(index = df[\"stars\"], columns = \"prop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13a2ff-559c-4745-b793-ab3859f72b70",
   "metadata": {
    "id": "ef13a2ff-559c-4745-b793-ab3859f72b70"
   },
   "outputs": [],
   "source": [
    "# Data set under assumption that 1, 2, and 3 are bad, 4 and 5 are good\n",
    "df[\"binary\"] = [\"Positive\" if x >= 4 else \"Negative\" for x in df[\"stars\"]]\n",
    "#binary\n",
    "\n",
    "pd.crosstab(index = df[\"binary\"], columns = \"prop\") / pd.crosstab(index = df[\"binary\"], columns = \"prop\").sum()\n",
    "df.to_csv(out_path_binary, columns = [\"text\", \"binary\"], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c6dfa-5242-4e67-a3f8-d6cb0d1af9ee",
   "metadata": {
    "id": "a08c6dfa-5242-4e67-a3f8-d6cb0d1af9ee"
   },
   "outputs": [],
   "source": [
    "# Data set under assumption that 1 and 2 are bad, 4 and 5 are good, and 3 is Neutral\n",
    "df[\"nominal\"] = [\"Positive\" if x >= 4 else \"Negative\" if x <= 2 else \"Neutral\" for x in df[\"stars\"]]\n",
    "pd.crosstab(index = df[\"nominal\"], columns = \"prop\") / pd.crosstab(index = df[\"nominal\"], columns = \"prop\").sum()\n",
    "\n",
    "df.to_csv(out_path_nominal, columns = [\"text\", \"nominal\"], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bb680-8055-4ee2-a472-96bfca4cdd74",
   "metadata": {
    "id": "d50bb680-8055-4ee2-a472-96bfca4cdd74"
   },
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd7c03-30bd-4908-bc5b-a7c81aea434c",
   "metadata": {
    "id": "0ebd7c03-30bd-4908-bc5b-a7c81aea434c"
   },
   "outputs": [],
   "source": [
    "input_path_nominal = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\Raw Data\\\\Yelp Data\\\\nominal.csv'\n",
    "input_path_binary = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\Raw Data\\\\Yelp Data\\\\binary.csv'\n",
    "path = 'C:\\\\Users\\\\coope\\\\OneDrive\\\\Desktop\\\\Side_Projects\\\\yelp_dataset\\\\total_data.csv'\n",
    "\n",
    "df = pd.read_csv(path, index_col = 0)\n",
    "#df = pd.read_csv(input_path_binary)\n",
    "#df = pd.read_csv(input_path_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5e91e-7aa2-4fe9-896e-e9c93dd312cc",
   "metadata": {
    "id": "22e5e91e-7aa2-4fe9-896e-e9c93dd312cc"
   },
   "outputs": [],
   "source": [
    "df_sample = df.sample(20000, random_state = 12345)\n",
    "\n",
    "#pd.crosstab(index = df[\"nominal\"], columns = \"prop\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( df_sample[\"text\"], df_sample[\"stars\"], test_size = 0.30, random_state = 12345)\n",
    "#X_train, X_test, y_train, y_test = train_test_split( df_sample[\"text\"], df_sample[\"nominal\"], test_size = 0.30, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0509b-c99e-4aa8-a83a-e26c8edab1d7",
   "metadata": {
    "id": "2cc0509b-c99e-4aa8-a83a-e26c8edab1d7"
   },
   "outputs": [],
   "source": [
    "# TF-IDF bag of n-grams pipeline and logistic regression\n",
    "pipeline_tfidf_LOG = Pipeline(steps = [('vectorizer', TfidfVectorizer(ngram_range = (1, 2))),\n",
    "                        ('classifier', LogisticRegression())])\n",
    "\n",
    "\n",
    "pipeline_tfidf_LOG.fit(X_train, y_train)\n",
    "pipeline_tfidf_LOG.score(X_test, y_test) # 62.017 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75877077-59de-4313-b076-75d7b1638d61",
   "metadata": {
    "id": "75877077-59de-4313-b076-75d7b1638d61"
   },
   "outputs": [],
   "source": [
    "# TF-IDF bag of n-grams pipeline and support vector machine (Linear)\n",
    "pipeline_tfidf_SVM_L = Pipeline(steps = [('vectorizer', TfidfVectorizer(ngram_range = (1, 2))),\n",
    "                        ('classifier', svm.LinearSVC())])\n",
    "\n",
    "\n",
    "pipeline_tfidf_SVM_L.fit(X_train, y_train)\n",
    "pipeline_tfidf_SVM_L.score(X_test, y_test) # 63.067%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8b926-69c4-4d79-a648-4d2525b3be38",
   "metadata": {
    "id": "deb8b926-69c4-4d79-a648-4d2525b3be38"
   },
   "outputs": [],
   "source": [
    "# TF-IDF bag of n-grams pipeline and Multinomial Naive Bayes\n",
    "pipeline_tfidf_MNB = Pipeline(steps = [('vectorizer', TfidfVectorizer(ngram_range = (1, 2))),\n",
    "                        ('classifier', MultinomialNB())])\n",
    "\n",
    "\n",
    "pipeline_tfidf_MNB.fit(X_train, y_train)\n",
    "pipeline_tfidf_MNB.score(X_test, y_test) # 42.883%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50880aea-ebea-42c2-a381-5c395cc51c63",
   "metadata": {
    "id": "50880aea-ebea-42c2-a381-5c395cc51c63"
   },
   "outputs": [],
   "source": [
    "# TF-IDF bag of n-grams pipeline and Complement Naive Bayes\n",
    "pipeline_tfidf_CNB = Pipeline(steps = [('vectorizer', TfidfVectorizer(ngram_range = (1, 2))),\n",
    "                        ('classifier', ComplementNB())])\n",
    "\n",
    "\n",
    "pipeline_tfidf_CNB.fit(X_train, y_train)\n",
    "pipeline_tfidf_CNB.score(X_test, y_test) # 45.467%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
